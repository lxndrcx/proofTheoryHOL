\documentclass[a4paper]{article}
\usepackage[a4paper,margin=2cm]{geometry}

\title{Equivalence of Natural Deduction and Sequent Calculus in HOL4\\
  \normalsize{} COMP3710 Report\\
  Funded by a AMSI Vacation Research Scholarship}
\author{Alexander Cox\thanks{Studying a Bachelor of Science at The Australian National University (ANU)}\\
      \small\texttt{u6060697@anu.edu.au}\\
      \normalsize{}Supervised by Dr Michael Norrish\thanks{Data61, CSIRO\@; ANU}}
\usepackage[backend=biber, style=authoryear-icomp] {biblatex}
\addbibresource{report.bib}

\usepackage{mathtools}
% \usepackage{fdsymbol}
\usepackage{amsthm}
\usepackage{thmtools, thm-restate}
\usepackage{
nameref,%\nameref
hyperref,%\autoref
cleveref,% \cref
}
\usepackage{upgreek}
% \usepackage{MnSymbol}
\usepackage{bussproofs}
\usepackage{proof}
\usepackage{alltt}
\usepackage{/Users/alexc/HOL/src/TeX/holtexbasic}
% \setlength\parindent{0pt}
% \newcommand{\textbf{N}}{\textbf{N}}
% \newcommand{\textbf{G}}{\textbf{G}}

% \newtheorem{thm}{Theorem}[subsection]
% \newtheorem{lem}[thm]{Lemma}
% \newtheorem{corl}[thm]{Corollary}
% \theoremstyle{definition}
% \newtheorem{defn}[thm]{Definition}
% \theoremstyle{remark}
% \newtheorem{notn}[thm]{Notation}
% \newtheorem{remk}[thm]{Remark}
\declaretheorem[numberwithin=subsection,name=Theorem]{thm}
% \declaretheorem[name=Theorem]{thm}
\declaretheorem[sibling=thm,name=Lemma]{lem}
\declaretheorem[sibling=thm,name=Corollary]{corl}
\declaretheorem[sibling=thm,style=definition,name=Definition]{defn}
\declaretheorem[sibling=thm,style=remark,name=Notation]{notn}
\declaretheorem[sibling=thm,style=remark,name=Remark]{remk}

\renewcommand{\HOLConst}[1]{\textsf{\upshape#1}}
\renewcommand{\HOLinline}[1]{\ensuremath{#1}}
\renewcommand{\HOLKeyword}[1]{\textbf{#1}}
\begin{document}
\maketitle

\begin{abstract}
  % TODO abstract
\end{abstract}

\section{Introduction}
In this project I have closely followed sections of \textcite{bpt} in it's presentation of Natural Deduction (\textbf{N}) and Sequent Calculus (\textbf{G}). I will note any deviances from this book which I have used.

% \subsection{Background}
\textbf{N} and \textbf{G} are logical calculi introduced by Gentzen in the mid 1930s.
\textbf{N} derives formulae from assumptions using introduction or elimination rules (which either introduce or eliminate a logical operator).
\textbf{G} derives sequents, which are a multisets of formulae related by the sequent relation (denoted $\vdash$). \textbf{G} has one axiom, in addition to left and right rules which operate on formulae in either the left or right of the sequent.
I have been formalising these proof systems for intuitionistic propositional logic.
In particular I have been mechanising the proof of equivalence between these two calculi.

The formalisation has taken place in the HOL4 Theorem Prover~\autocite{HOLbrief}, henceforth referred to as HOL\@.


% \paragraph{Motivation}
% why bother?
The purpose of this project was for me to learn how to use an interactive theorem prover. The proof theory itself is well known, and has been formalised before, albeit in a slightly different manner.

\subsection{The HOL Theorem Prover}
HOL is an interactive theorem prover which implements Higher Order Logic as the meta-logic with which users formalise mathematics.
HOL implements Church's Simple Theory of Types with polymorphic types~\autocite{HOLbrief}.
HOL is implemented with Standard ML, and this is the meta-language and main interface to HOL.

Proving a theorem in HOL guarantees that your proof is correct and the theorem is sound, under the assumption that HOL is itself sound. All theorems in HOL are generated from the composition of a small set of axioms and basic inference rules, which are considered trusted by the HOL community. HOL can be built using two different Standard ML compilers, which increases confidence that the soundness of HOL is compiler-independent. HOL can also produce a certificate of correctness which can then be checked by another theorem prover, as an additional measure to establish trust in soundness. Saying this, any proof relies on first having a correct specification and formulation of the mathematical content. If I have not formalised my definitions correctly, my proofs don't establish the truth of theorems concerning the correct definitions.

HOL has good support for inductively defined relations~\autocite{cam92}, which I used in this project. HOL automatically proves a strong induction theorem for the defined relations, which can then be used to perform rule induction on the relation~\autocite{cam92}.

\subsection{Related Work}
The equivalence of Natural Deduction, Sequent Calculus and Hilbert calculus for classical propositional logic, has been formalised in the theorem prover Coq, by \textcite{ptcoq}.
A major difference between my formalisation and that of \citeauthor{ptcoq} is that they used lists for their contexts in both \textbf{N} and \textbf{G}, whereas I have used sets and multisets respectively.
They also mechanised the proofs of soundness and completeness.

The same equivalence, but for first order classical logic, has been formalised in HOL by \textcite{fopthol}.
They also mechanised the proofs of deduction monotonicity and compactness, amongst others. The latter was formalised quite differently to the way I have formalised the calculi in this project, using several additional purpose-built datatypes, such as one for derivations.

\section{Formalisation in HOL}
  % (give definitions and theorem statements; explain interesting proofs)

\subsection{Syntax}
I formalised the intuitionistic logic versions of \textbf{N} and \textbf{G}, referred to as \textbf{Ni} and \textbf{G2i} in \textcite{bpt}.

\begin{defn}[Formula]

  The formulae of intuitionistic propositional logic are defined inductively, starting with atomic variables of arbitrary type $\alpha$, then connected with logical operators. I have used non-standard symbols $\veebar$ and $\barwedge$ in place of $\vee$ and $\wedge$ to avoid confusion with the meta-logical symbols used. The operators are defined in prefix form, but are always used as infix operators afterwards\footnote{This is how they are defined in HOL}.

  Here is how formulae are defined in BNF syntax:
  \[ \varphi ::= \alpha~|~\varphi \veebar \varphi~|~\varphi \barwedge \varphi~|~\varphi \to \varphi~|~\bot \]
  where $\varphi$ is a formula and $\alpha$ is an atomic variable.

  Here is the corresponding HOL definition:
  \begin{HOLmath}
    \HOLthm{FormulaSyntax.datatype_formula}
  \end{HOLmath}
  \begin{notn}
    The latter definition is produced by HOL for typesetting. For illustration purposes, here is how I wrote it in my text editor:

    \begin{alltt}
    val _ = Datatype `formula =
        Var 'a
        | Or formula formula
        | And formula formula
        | Imp formula formula
        | Bot`;
    \end{alltt}

    For the remainder of the report I will use typeset versions of definitions and theorems produced by HOL.
  \end{notn}

\end{defn}

% \subsection{Notation}
% I will now explain the notation I will use in this report.



\begin{notn}
  I use $A,B,C$ for arbitrary formulae.
\end{notn}

\begin{defn}[Abbreviations]

  The remainder of propositional logic syntax is achieved with abbreviations:

  \begin{HOLmath}
    \HOLthm[nosp]{FormulaSyntax.Not_def}\\
    \HOLthm[nosp]{FormulaSyntax.BiImp_def}\\
    \HOLthm[nosp]{FormulaSyntax.Top_def}
  \end{HOLmath}
\end{defn}


\subsection{Natural Deduction (\textbf{N})}
  I have represented \textbf{N} in sequent style~\autocite[s. 2.1.8]{bpt} using the complete discharge convention~\autocite[s. 2.1.9]{bpt}. This means that rather than having a tree with assumptions as leaves, I have sequents, with a set of open assumptions on the left. Open assumptions are assumptions which have not been discharged.

  The complete discharge convention says that I can discharge all instances of a assumption at once, rather than keeping track of assumptions with labels. This simplifies the presentation of Natural Deduction. The rules which discharge assumptions are $\to$i and $\veebar$e, which I define below.

\begin{notn}
  $\Gamma \vdash_S A$ denotes that the formula $A$ can be derived from the hypotheses $\Gamma$ in proof system $S$. A $\vdash$ by itself denotes a theorem in the meta-logic, HOL.
\end{notn}

% I have represented the infix sequent relation $\vdash_{\textbf{N[mi]}}$ as a prefix relation \texttt{N[mi]}.

\begin{defn}[The \textbf{N} calculus]

  \begin{HOLmath}
    \HOLthm[rule,rulename=ax,conj1]{pp.N_rules'}
    \hspace{0.5cm}
    \HOLthm[rule,rulename=$\barwedge$i,conj2]{pp.N_rules'}
    \hspace{0.5cm}
    \HOLthm[rule,rulename=$\barwedge$el,conj3]{pp.N_rules'}
    \hspace{0.5cm}
    \HOLthm[rule,rulename=$\barwedge$er,conj4]{pp.N_rules'}\\\\
    \HOLthm[rule,rulename=$\to$i,conj5]{pp.N_rules'}
    \hspace{0.5cm}
    \HOLthm[rule,rulename=$\to$e,conj6]{pp.N_rules'}
    \hspace{0.5cm}
    \HOLthm[rule,rulename=$\bot$e,conj10]{pp.N_rules'}\\\\
    \HOLthm[rule,rulename=$\veebar$il,conj7]{pp.N_rules'}
    \hspace{0.5cm}
    \HOLthm[rule,rulename=$\veebar$ir,conj8]{pp.N_rules'}
    \hspace{0.5cm}
    \HOLthm[rule,rulename=$\veebar$e,conj9]{pp.N_rules'}
  \end{HOLmath}

\end{defn}

\begin{notn}
  Equations in this text starting with a $\vdash$ are exported theorems from HOL, and have been specialised (universal quantifiers have been stripped). For example, the finiteness property for \textbf{N} is as follows, first specialised, then not-specialised:
  \begin{corl}[\textbf{N} hypotheses are finite]
    \begin{HOLmath}
      \HOLthm{IntuitionisticProof.N_FINITE}\\
      \HOLthm[nosp]{IntuitionisticProof.N_FINITE}
    \end{HOLmath}
  \end{corl}
  I will use the specialised versions for the remainder of the text.
\end{notn}

\begin{defn}[The \textbf{Nd} calculus]

  The definition of \textbf{N} in \textcite{bpt} has different rules when discharging assumptions, which I formalised as \textbf{Nd}. Rather than having singleton unions above the line, they have singleton set differences below the line. Here are the rules which differ:

  \begin{HOLmath}
    \HOLthm[rule,rulename=$\to$i,conj5]{pp.Nd_rules'}
    \hspace{1.0cm}
    \HOLthm[rule,rulename=$\veebar$e,conj9]{pp.Nd_rules'}
  \end{HOLmath}

\end{defn}

\begin{lem}[\textbf{N} weakening]\label{Nlw} \HOLthm{pp.N_lw'} \end{lem}
\begin{lem}[\textbf{Nd} weakening]\label{Ndlw} \HOLthm{pp.Nd_lw'} \end{lem}

\begin{proof}
  Both proofs are the same, just replace \textbf{N} for \textbf{Nd} for the other. The proof is by construction:
  \[
    \infer[\barwedge\text{e}]
    {\HOLtm{((B INSERT EMPTY) UNION D) N A}}
    {\infer[\barwedge\text{i}]{\HOLtm{((B INSERT EMPTY) UNION D) N (A And B)}}
    {\infer*{\HOLtm{D N A}}{} &\infer[\text{ax}]{\HOLtm{(B INSERT EMPTY) N B}}{}}}
  \]
\end{proof}

Weakening can be extended as much as you like:
\begin{lem}[\textbf{N} superset weakening]\label{NlwSUBSET} \HOLthm{IntuitionisticProof.N_lw_SUBSET} \end{lem}
\begin{lem}[\textbf{Nd} superset weakening]\label{NdlwSUBSET}\HOLthm{IntuitionisticProof.N_lw_SUBSET} \end{lem}

\begin{proof}
  By induction on the cardinality of \HOLtm{D'}. You can insert as many formulae as you like.
\end{proof}


\begin{thm}[\textbf{N} is equivalent to \textbf{Nd}]
  Given the same hypotheses, the same formulae can be derived from both formulations of natural deduction:
  \begin{HOLmath}
    \HOLthm{IntuitionisticProof.N_Nd}
  \end{HOLmath}
\end{thm}

\begin{proof}[if]
  Proof by rule induction on \textbf{N}.
  Automatic rewrites and first-order automated reasoning prove the cases which coincide.
  The $\to$i and $\veebar$e cases are proved by using the corresponding inference rule, using \textbf{Nd} weakening, and appealing to the fact that \HOLtm{((A INSERT EMPTY) UNION D) DIFF (A INSERT EMPTY) = D}.
\end{proof}

\begin{proof}[only if]
  Proof by rule induction on \textbf{Nd}.
  Automatic rewrites and first-order automated reasoning prove the cases which coincide.
  The $\to$i and $\veebar$e cases are proved using \textbf{N} weakening.
\end{proof}

\subsection{Sequent Calculus (\textbf{G})}
I am using \textbf{G2i} in this project, as that is what was used in the book for the equivalence proof~\autocite[s. 3.1.6]{bpt}. \textbf{G2i} has the weakening rules absorbed into the axiom and absurdity rules, but contains distinct contraction rules. Unlike \textbf{G2c} (classical logic), the conclusion is a single formula, rather than a bag of formulae.

\begin{defn}
  Bags (a.k.a. multisets) are sets with duplicates permitted. In HOL bag is a function type: \textsf{bag:}\HOLty{:'a bag}, where \HOLty{:'a} is a type variable.
\end{defn}

\begin{notn} The empty bag is denoted \HOLtm{EMPTY_BAG}. \end{notn}

\begin{remk}
  I use \autocite[lemma 3.1.8]{bpt} to eliminate empty succedents which are possible in \textbf{G2i}, but cause added complexity in formalisation. The only conclusion this removes from the calculus is the empty bag. If I had not done this, the consequent of the $\bot$ rule would instead be \HOLtm{EMPTY_BAG}, and the conclusions of the other rules would be singleton bags of formulae rather than formulae.
\end{remk}

\begin{notn} Elements of bags are separated by semicolons. For example, \HOLtm{BAG_INSERT A (BAG_INSERT B (BAG_INSERT B EMPTY_BAG))} is the bag containing three elements, one occurrence of \HOLtm{A} and two of \HOLtm{B}. \end{notn}

\begin{defn} The union of two bags, denoted \HOLtm{BAG_UNION b c} is the sum of the element counts.
  \begin{HOLmath}
    \HOLthm{bag.BAG_UNION}
  \end{HOLmath}
\end{defn}

\begin{defn}[The \textbf{G} Calculus]

  \begin{HOLmath}
    \HOLthm[rule,rulename=ax,conj1]{pp.G_rules'}
    \hspace{0.5cm}
    \HOLthm[rule,rulename=L$\bot$,conj2]{pp.G_rules'}
    \hspace{0.5cm}
    \HOLthm[rule,rulename=cont,conj3]{pp.G_rules'}\\\\
    \HOLthm[rule,rulename=L$\barwedge$L,conj4]{pp.G_rules'}
    \hspace{0.5cm}
    \HOLthm[rule,rulename=L$\barwedge$R,conj5]{pp.G_rules'}
    \hspace{0.5cm}
    \HOLthm[rule,rulename=R$\barwedge$,conj6]{pp.G_rules'}\\\\
    \HOLthm[rule,rulename=L$\veebar$,conj7]{pp.G_rules'}
    \hspace{0.5cm}
    \HOLthm[rule,rulename=R$\veebar$L,conj8]{pp.G_rules'}
    \hspace{0.5cm}
    \HOLthm[rule,rulename=R$\veebar$R,conj9]{pp.G_rules'}\\\\
    \HOLthm[rule,rulename=L$\to$,conj10]{pp.G_rules'}
    \hspace{0.5cm}
    \HOLthm[rule,rulename=R$\to$,conj11]{pp.G_rules'}
    \hspace{0.5cm}
    \HOLthm[rule,rulename=cut,conj12]{pp.G_rules'}
  \end{HOLmath}

\end{defn}

\begin{corl}[Hypotheses in \textbf{G} are finite]\label{GFINITE}
    \HOLthm{IntuitionisticProof.G_FINITE}
\end{corl}

\subsection{Bag lemmata}
Recall that bags are multisets, defined as a characteristic function returning the number of occurrences of a given element. This definition comes from the provided `bag theory' in HOL, which defines and proves propositions concerning bags. HOL's bag theory was insufficient for my project, so I have extended it with 25 additional results, which have been merged into HOL for others to use if they wish (see \ref{appendix} for list).
\begin{defn} The function \textsf{bag: set $\mapsto$ bag} converts sets into bags. This should not be confused with the datatype \textsf{bag:}~\HOLty{:'a bag}. \end{defn}
\begin{defn} The function \textsf{set: bag $\mapsto$ set} converts bags into sets. Again, not to be confused with the datatype \textsf{set:}~\HOLty{:'a set} \end{defn}
\begin{defn} The function \textsf{unibag: bag $\mapsto$ bag} converts bags into sets and then back again.  \end{defn}
\begin{notn} \HOLtm{b e} is the number of occurrences of the element \HOLtm{e} in the bag \HOLtm{b}.  \end{notn}
\begin{defn} A bag is distinct if no elements 1 occur more than once. \HOLthm{bag.BAG_ALL_DISTINCT} \end{defn}
\begin{corl}[Unibags are distinct] \HOLthm{bag.unibag_ALL_DISTINCT} \end{corl}

I needed unibags in order to reason about contraction of hypotheses in \textbf{G}. To make a bag of hypotheses a unibag is to make them equivalent to a set of hypotheses, which is necessary in the equivalence proof to come later. The main result concerning unibags was the following:
\begin{thm}[Complete contraction]\label{Gunibag} \HOLthm{IntuitionisticProof.G_unibag} \end{thm}

\begin{proof}

  \textit{(if)} By \textbf{G} weakening.

  \textit{(only if)} By induction on the cardinality of \HOLtm{Gamma}, then an application of the \textsf{cont} (contraction) rule.
\end{proof}

\begin{defn} The merge of two bags, denoted \HOLtm{b BAG_MERGE c} is the pointwise maximum of the element counts.
  \begin{HOLmath}
    \HOLthm{bag.BAG_MERGE}
  \end{HOLmath}
\end{defn}

\begin{lem}[Bag of set union]\label{bosu}
  When applied to a set union, \HOLtm{BAG_OF_SET} returns a bag merge with the \HOLtm{BAG_OF_SET} applied to each set.
  \begin{HOLmath} \HOLthm{bag.BAG_OF_SET_UNION} \end{HOLmath}
\end{lem}

\subsection{Proof of Equivalence}

\begin{notn}
  When I give the HOL tactics of my proofs, I will present them as they are typed in my HOL code. HOL doesn't remember how something is proved, so it can't give a typeset version that I can use. The main thing to note is that the deducibility relations \HOLtm{$G} and \HOLtm{$N} are given in prefix from in my code, and are just typed \texttt{G} and \texttt{N}. I explain other differences with the proofs.
\end{notn}

\begin{lem}[\textbf{G} weakening]
  Since weakening is built into the axiom of \textbf{G}, I have proved a lemma to use as a weakening rule. The hypotheses of a sequent can be extended to any finite superset of those hypotheses.
  \begin{HOLmath} \HOLthm{IntuitionisticProof.G_lw} \end{HOLmath}
\end{lem}

\begin{lem}[From \textbf{N} to \textbf{G}]\label{NG}
  \begin{HOLmath}
    \HOLthm{IntuitionisticProof.N_G}
  \end{HOLmath}
\end{lem}

\begin{proof}
  The proof is by rule induction~\autocite[see][6--7]{cam92} on \textbf{N}. Given a instance of an inference rule in \textbf{N}, I must construct a proof in \textbf{G} with the same hypotheses and conclusion.

  Three cases are proven by a single rewrite with the rules of \textbf{G}, those corresponding to \textbf{N} rules: \textsf{ax, $\veebar$il and $\veebar$ir}.
  The introduction rule cases of \textbf{N} generally are translated into the right rules of \textbf{G}. The elimination rules translate to an instance of the corresponding left rule, plus an instance of \textsf{cut}.

  Here is the construction for the \textsf{$\bot$e} case, the next shortest case:
  \[
    \AxiomC{$\vdots$}
    \RightLabel{(IH)}
    \UnaryInfC{\HOLtm{(BAG_OF_SET D) G Bot}}
    \AxiomC{}
    \RightLabel{\textsf{L$\bot$}}
    \UnaryInfC{\HOLtm{(BAG_INSERT Bot EMPTY_BAG) G A}}
    \RightLabel{\textsf{cut}}
    \BinaryInfC{\HOLtm{(BAG_OF_SET D) G A}}
    \DisplayProof
  \]

Here are the HOL tactics which prove this case:
\begin{alltt}
  `G \{|Bot|\} A` by metis_tac[G_bot,BAG_IN_BAG_INSERT,FINITE_BAG] >>
  metis_tac[G_cut,BAG_UNION_EMPTY]
\end{alltt}
\texttt{metis\_tac} is the first order reasoner, which takes a \texttt{thm list}, where a thm is the datatype of propositions which have been proved in HOL. \texttt{Bot} is \HOLtm{Bot}, thms starting with \texttt{G_} are the names of \textbf{G} rules. BAG\_IN\_BAG\_INSERT proves that \HOLtm{BAG_IN Bot (BAG_INSERT Bot EMPTY_BAG)}, FINITE\_BAG proves that the hypothesis is finite and BAG\_UNION\_EMPTY removes the empty bag which \textsf{cut} introduces.

While in the previous construction matches quite closely with the informal proof, for some cases I used tactics which are less similar in appearance.
Here are the HOL tactics for the \textsf{$\to$i} case:
\begin{alltt}
  irule G_rimp >>
  fs[BAG_OF_SET_INSERT] >>
  irule G_lw >>
  simp[] >>
  drule G_FINITE >>
  rw[] >>
  qexists_tac `BAG_MERGE \{|A|\} (BAG_OF_SET D)` >>
  simp[BAG_MERGE_ELBAG_SUB_BAG_INSERT]
\end{alltt}
These tactics are in a backwards-proof style. \texttt{irule} reduces the goal (conclusion) to the antecedent of the supplied thm.
BAG\_OF\_SET\_INSERT is an instance of bag of set union limited to singleton union.
\texttt{G_lw} is \textbf{G} weakening.
\texttt{drule} uses an assumption which matches the antecedent of the supplied thm and introduces the conclusion of that thm as an antecedent to the goal, this is like modes ponens.
\texttt{rw} aggresively rewrites the goal using known rewrite rules, plus any thms provided (none here).
\texttt{qexists\_tac} supplies a witness to an existential goal.
\texttt{simp} rewrites the goal using known rewrites and supplied thms. \texttt{BAG\_MERGE\_ELBAG\_SUB\_BAG\_INSERT} says that a bag merge of a singleton and a bag is a sub-bag of a bag union of a singleton and a bag.


\begin{alltt}
  simp[BAG_OF_SET_UNION] >>
  `FINITE_BAG (BAG_OF_SET D')` by metis_tac[N_FINITE,FINITE_BAG_OF_SET] >>
  `G (BAG_INSERT A' (BAG_OF_SET D')) A'`
    by simp[G_ax,BAG_IN_BAG_INSERT] >>
  `G (BAG_INSERT (A Imp A') (BAG_OF_SET D')) A'`
    by metis_tac[G_limp] >>
  `G ((BAG_OF_SET D) + (BAG_OF_SET D')) A'`
    by metis_tac[G_cut] >>
  `G (unibag (BAG_OF_SET D + BAG_OF_SET D')) A'` by metis_tac[G_unibag] >>
  fs[unibag_UNION]
\end{alltt}

\end{proof}

The following two lemmata form the main part of my formalisation, and are used together to prove the main theorem.

\begin{lem}[From \textbf{G} to \textbf{N}]\label{GN}
  \begin{HOLmath}
    \HOLthm{IntuitionisticProof.G_N}
  \end{HOLmath}
\end{lem}

\begin{proof}
  The proof is by rule induction on \textbf{G}.

\end{proof}
The following is the primary theorem of this project:

\begin{thm}[Proof of equivalence between \textbf{N} and \textbf{G}]\label{GiffN}

  Given the same hypotheses, modulo weakening, the same formulae are provable in both calculi. This is Theorem 3.3.1 in \textcite{bpt}.
  \begin{HOLmath}
    \HOLthm{IntuitionisticProof.G_iff_N}
  \end{HOLmath}
\end{thm}
\begin{proof}
  \textit{(only if)} by \cref{GN}.\\

  \noindent
  \textit{(if)} by \cref{NG} and \cref{Gunibag} (Complete contraction).
\end{proof}

\section{Discussion of Issues} %(bags)
% HOL is monstrous to learn, doc s hard to read. Bags are a mess. etc
%learning tacs is hard because so many, so i did a lot of verbose declarative stuff.
% de Bruijn factor
\subsection{Learning Curve}
I found HOL to have quite a steep learning curve. Several weeks were dedicated to learning how to prove basic propositions which are trivial to prove on paper. Knowing a proof does not help much if you do not know how to use the theorem prover. I found that the documentation was difficult read, as it is very technical once you get past the tutorial. However, I now have gained some confidence in HOL, and its particularities make more sense now that I am used to them.

The difficulty lies not just in understanding how HOL works, but also in remembering and knowing how to find the tools that will prove your proposition. HOL implements \emph{goal directed} proof as a method of proving theorems, and this is what I used to prove all of the results in this project. To prove a goal in HOL, one uses \emph{tactics}, which help to construct a proof starting with the desired conclusion. There are many tactics available in HOL, most of which I have not used and don't understand. In addition there is a library of theories which contain theorems which can be used by some tactics as lemmata to advance towards the goal. The combined number of options is intimidating at first, but I found that only a small subset of these tools were necessary for the purposes of this project.

\subsection{Bag Theory}
A significant portion of effort in this project was dedicated to proving lemmata concerning bags. As discussed earlier, the existing bag theory in HOL contained only some of the results which I needed, so I had to prove them myself. The bag theory in HOL is also somewhat confusing in it's formulation. For example, there is a ternary relation called \textsf{BAG_DELETE} which is defined \HOLthm[def,tt]{bag.BAG_DELETE}, in contrast to the set theory binary relation called \textsf{DELETE} which is defined \HOLthm[def,tt]{pred_set.DELETE_DEF}. The first is used to relate two bags, one of which has already had an element deleted, the second (more intuitively) is a function which deletes an element from a set.

In the process of proving the necessary bag lemmata, I often found myself looking at a mess of conditionals inside lambda abstractions. For a simple example, suppose I wanted to prove that \HOLtm{(BAG_OF_SET s) - b = (BAG_OF_SET (s DIFF (SET_OF_BAG b)))} and I expand the definitions of the operators, I get:
\begin{HOLmath}
  \HOLtm{(λx. (if s x then 1 else 0) − b x) = (λx. if s x ∧ ¬(b x ≥ 1) then 1 else 0)}.
\end{HOLmath}
The only way I found to prove a goal like this is to use \textsf{FUN_EQ_THM}:\HOLthm{bool.FUN_EQ_THM}, a theorem which does not mention lambda abstractions nor conditionals, so took some time for me to find.

\subsection{Summary of effort}
The effort and time required to formalise mathematics in HOL is more than that which it takes to cover the same content informally. After a few weeks learning to use HOL, another full month has been spent formalising content which I understood after only a day or two of reading \textcite{bpt}. In total I have spent over 40 hours learning HOL, and 90 hours formalising the relevant proof theory.


\section{Future Work}
% Summary of effort/Future Work/What'd I'd do differently
% abstract derivation relation, which you give a set of inference rules, much more flexible and less redundancy in script.sml. Better for cut/cutfree stuff
% prove cutfree stuff, relationship to normalised nd derivations
% classical, predicate
\subsection{Extensions of the proof}
\subsubsection{Classical Logic}
I would have liked to have formalised the proof for classical logic as well as intuitionistic logic, but I was unable to due to time. I did make some progress, but due to the differences between the classical absurdity rules of Natural Deduction and Sequent Calculus, extra work is required which I have not completed. The rest of the rules did not seem to cause any significant difficulty, and in fact I was able to prove all cases of $\textbf{N} \Rightarrow \textbf{G}$, except for the negation case, in a single afternoon.

Here are the negation rules in question. Note that in classical sequent calculus the consequent is a bag of formulae rather than an individual formula:
\begin{HOLmath}
  \HOLthm[rule,rulename=$\bot_c$e,conj10]{pp.Nc_rules}
  \hspace{0.5cm}
  \HOLthm[rule,rulename=L$\bot_c$,conj2]{pp.Gc_rules}
\end{HOLmath}

\Citeauthor{bpt} leave the proof of equivalence for classical logic as an exercise for the reader~\autocite[Thm. 3.3.3]{bpt}.

\subsubsection{First Order Logic}
I would have liked to have extended the proof to first order logic. In future it would be interesting to do so. The first order proof contains the propositional one I have done, and they do not separate them in \textcite[Sec. 3.3]{bpt}.

\subsubsection{Cut-free proofs and Normalisation}
A substantial part of \textcite{bpt} is dedicated to cut-free sequent calculus (\textbf{G} without the cut rule), and there is a proof that this is equivalent to normalised natural deduction~\autocite[Sec. 6.3.1]{bpt}. Cut-free sequent calculus is interesting because it has the subformula property, that is, in any proof of \HOLtm{Gamma G Delta}, only subformulae of \HOLtm{Gamma} and \HOLtm{Delta} appear. This has many applications, for example, propositional intuitionistic logic is decidable, and a decision procedure exists in a cut-free sequent calculus~\autocite[Thm. 4.2.6]{bpt}.

\subsection{Other Proof Theory}
Other calculi of interest to me are those for modal logics. \Citeauthor{bpt} present a sequent calculus for \textbf{S4}, and prove that intuitionistic logic can be embedded into it~\autocite[Sec. 9.2]{bpt}. This would have been more interesting to formalise, but I expect would have been more challenging as I have less experience with calculi of non-classical logics. There are many modal logics and multiple calculi for each, so there is a room for more original formalisation in this area.

\subsection{Flexible sets of rules}
The main improvement I would have liked to have made to my formalisation is a significant alteration in how the proof systems are defined. Since there are many variants of the proof systems, and many of these build upon each other, it would be optimal to be able to specify a set of inference rules rather than redefine all of the redundant rules each time I want to define a deducibility relation for a system.

This would allow me to define a set of cut-free sequent calculus rules, and then add the cut rule to them to form cut-full sequent calculus, for example.

This modification to my formalisation would make the other extensions I considered easier to implement, and would also decrease clutter in the HOL code.

\section{Conclusion}
\subsection{Acknowledgements}

\printbibliography
\newpage
\section{Appendix}\label{appendix}
\subsection{Bag Lemmata}
This is a list of the theorems I have formalised in HOL.
The source for this project can be found at \url{https://github.com/lxndrcx/proofTheoryHOL}.
In addition, the following bag and unibag lemmata I wrote have been merged into HOL, see \url{https://github.com/HOL-Theorem-Prover/HOL/pull/654}.
I have given the theorem names as they appear in HOL.

\begin{lem}[\texttt{BAG\_MERGE\_SUB\_BAG\_UNION}]             \HOLthm{bag.BAG_MERGE_SUB_BAG_UNION}             \end {lem}
\begin{lem}[\texttt{BAG\_MERGE\_EMPTY}]                       \HOLthm{bag.BAG_MERGE_EMPTY}                     \end {lem}
\begin{lem}[\texttt{BAG\_MERGE\_ELBAG\_SUB\_BAG\_INSERT}]     \HOLthm{pp.BAG_MERGE_ELBAG_SUB_BAG_INSERT'}      \end {lem}
\begin{lem}[\texttt{BAG\_MERGE\_EQ\_EMPTY}]                   \HOLthm{bag.BAG_MERGE_EQ_EMPTY}                  \end {lem}
\begin{lem}[\texttt{BAG\_INSERT\_EQ\_MERGE\_DIFF}]            \HOLthm{pp.BAG_INSERT_EQ_MERGE_DIFF'}            \end {lem}
\begin{lem}[\texttt{BAG\_MERGE\_BAG\_INSERT}] \begin{HOLmath} \HOLthm{pp.BAG_MERGE_BAG_INSERT'}                \end {HOLmath} \end {lem}
\begin{lem}[\texttt{BAG\_OF\_SET\_UNION}]                     \HOLthm{bag.BAG_OF_SET_UNION}                    \end {lem}
\begin{lem}[\texttt{BAG\_OF\_SET\_INSERT}]                    \HOLthm{pp.BAG_OF_SET_INSERT'}                   \end {lem}
\begin{lem}[\texttt{BAG\_OF\_SET\_BAG\_DIFF\_DIFF}]           \HOLthm{bag.BAG_OF_SET_BAG_DIFF_DIFF}            \end {lem}
\begin{lem}[\texttt{SET\_OF\_EL\_BAG}]                        \HOLthm{pp.SET_OF_EL_BAG'}                       \end {lem}
\begin{lem}[\texttt{BAG\_OF\_SET\_EQ\_INSERT}]                \HOLthm{pp.BAG_OF_SET_EQ_INSERT'}                \end {lem}
\begin{lem}[\texttt{FINITE\_BAG\_MERGE}]                      \HOLthm{bag.FINITE_BAG_MERGE}                    \end {lem}
\begin{lem}[\texttt{BAG\_MERGE\_CARD}] \begin{HOLmath}        \HOLthm{bag.BAG_MERGE_CARD}                      \end {HOLmath} \end {lem}
\begin{lem}[\texttt{BAG\_ALL\_DISTINCT\_SUB\_BAG}]            \HOLthm{bag.BAG_ALL_DISTINCT_SUB_BAG}            \end {lem}
\begin{defn}
  \HOLtm{BAG_FILTER P b} returns b filtered to include only elements of P:\footnote{Not my definition, just included to explain next lemma}
  \begin{HOLmath} \HOLthm{bag.BAG_FILTER_DEF} \end{HOLmath}
\end{defn}
\begin{lem}[\texttt{BAG\_OF\_SET\_DIFF}]   \HOLthm{bag.BAG_OF_SET_DIFF}                                        \end {lem}
\begin{lem}[\texttt{FINITE\_BAG\_OF\_SET}] \HOLthm{bag.FINITE_BAG_OF_SET}                                      \end {lem}

\subsection{Unibag Lemmata}
% TODO define unibags
\begin{lem}[\texttt{unibag\_INSERT}]                           \HOLthm{pp.unibag_INSERT'}         \end {lem}
\begin{lem}[\texttt{unibag\_UNION}]                            \HOLthm{bag.unibag_UNION}          \end {lem}
\begin{lem}[\texttt{BAG\_IN\_unibag}]                               \HOLthm{bag.BAG_IN_unibag}             \end {lem}
\begin{lem}[\texttt{unibag\_EQ\_BAG\_INSERT}]                  \HOLthm{pp.unibag_EQ_BAG_INSERT'}  \end {lem}
\begin{lem}[\texttt{unibag\_FINITE}]\label{unibagFINITE}       \HOLthm{bag.unibag_FINITE}         \end {lem}
\begin{lem}[\texttt{unibag\_ALL\_DISTINCT}]                    \HOLthm{bag.unibag_ALL_DISTINCT}   \end {lem}
\begin{lem}[\texttt{unibag\_EL\_MERGE\_cases}] \begin{HOLmath} \HOLthm{pp.unibag_EL_MERGE_cases'} \end {HOLmath} \end {lem}
\begin{lem}[\texttt{unibag\_DECOMPOSE}]                        \HOLthm{bag.unibag_DECOMPOSE}      \end {lem}
\begin{lem}[\texttt{unibag\_SUB\_BAG}]\label{unibagSUBBAG}     \HOLthm{bag.unibag_SUB_BAG}        \end {lem}

\subsection{Main Lemmata and Theorems}

\begin{lem}[\texttt{N\_FINITE}]          \HOLthm{IntuitionisticProof.N_FINITE}       \end {lem}
\begin{lem}[\texttt{N\_lw}]              \HOLthm{pp.N_lw'}                           \end {lem}
\begin{lem}[\texttt{Nd\_lw}]             \HOLthm{pp.Nd_lw'}                          \end {lem}
\begin{lem}[\texttt{N\_lw\_SUBSET}]      \HOLthm{IntuitionisticProof.N_lw_SUBSET}    \end {lem}
\begin{lem}[\texttt{Nd\_lw\_SUBSET}]     \HOLthm{IntuitionisticProof.Nd_lw_SUBSET}   \end {lem}
\begin{lem}[\texttt{N\_impi\_DELETE}]    \HOLthm{pp.N_impi_DELETE'}                  \end {lem}
\begin{thm}[\texttt{N\_Nd}]              \HOLthm{IntuitionisticProof.N_Nd}           \end {thm}
\begin{lem}[\texttt{G\_FINITE}]          \HOLthm{IntuitionisticProof.G_FINITE}       \end {lem}
\begin{lem}[\texttt{G\_lw}]\label{Glw}   \HOLthm{IntuitionisticProof.G_lw}           \end {lem}
\begin{lem}[\texttt{G\_lw\_BAG\_INSERT}] \HOLthm{pp.G_lw_BAG_INSERT'}                \end {lem}
\begin{lem}[\texttt{G\_lw\_BAG\_MERGE}]  \HOLthm{IntuitionisticProof.G_lw_BAG_MERGE} \end {lem}
\begin{lem}[\texttt{G\_lw\_BAG\_UNION}]  \HOLthm{IntuitionisticProof.G_lw_BAG_UNION} \end {lem}
\begin{lem}[\texttt{G\_unibag}]          \HOLthm{IntuitionisticProof.G_unibag}       \end {lem}
\begin{lem}[\texttt{N\_G}]               \HOLthm{IntuitionisticProof.N_G}            \end {lem}
\begin{lem}[\texttt{G\_N}]               \HOLthm{IntuitionisticProof.G_N}            \end {lem}
\begin{thm}[\texttt{G\_iff\_N}]          \HOLthm{IntuitionisticProof.G_iff_N}        \end {thm}

\end{document}
